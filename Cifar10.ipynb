{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       label\n",
       "0   1        frog\n",
       "1   2       truck\n",
       "2   3       truck\n",
       "3   4        deer\n",
       "4   5  automobile"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "labels = pd.read_csv(\"/Users/mingliangang/Desktop/cifar10/trainLabels.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label2id = {x:i for i,x in enumerate(list(set(labels[\"label\"])))}\n",
    "id2label = {i:x for i,x in enumerate(list(set(labels[\"label\"])))}\n",
    "labelcon = lambda x: label2id[x]\n",
    "labels['label'] = labels['label'].map(labelcon)\n",
    "labels_ = labels['label'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    5\n",
       "2    5\n",
       "3    7\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['label'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 5, ..., 5, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          frog\n",
       "1         truck\n",
       "2         truck\n",
       "3          deer\n",
       "4    automobile\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['label'].map(lambda x: id2label[x]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "train = np.array([cv2.imread(\"/Users/mingliangang/Desktop/cifar10/train/\"+i) for i in os.listdir(\"/Users/mingliangang/Desktop/cifar10/train\")]).astype(np.float32)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, labels_, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33500, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet Model (CIFAR 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n"
     ]
    }
   ],
   "source": [
    "from models import resnet\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 128\n",
    "GPU = True\n",
    "summaries_dir = \"/Users/mingliangang/Desktop/resnet2/\"\n",
    "decay = 2e-4\n",
    "if GPU:\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        X = tf.placeholder(\"float\", [batch_size, 32, 32, 3])\n",
    "        Y = tf.placeholder(\"float\", [batch_size, 10])\n",
    "        label = tf.placeholder(\"int64\",[batch_size])\n",
    "        learning_rate = tf.placeholder(\"float\", [])\n",
    "        \n",
    "        global_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n",
    "        \n",
    "        net = resnet(X,20)\n",
    "        \n",
    "        cross_entropy = -tf.reduce_sum(Y*tf.log(net))\n",
    "        loss = cross_entropy + decay*tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        correct_prediction = tf.equal(label,tf.argmax(net,axis=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        \n",
    "        opt = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "        train_op = opt.minimize(loss,global_step=global_step_tensor)\n",
    "        \n",
    "    merged = tf.summary.merge_all()\n",
    "    config = tf.ConfigProto(allow_soft_placement = True)\n",
    "    sess = tf.Session(config = config)\n",
    "    writer = tf.summary.FileWriter(summaries_dir + '/gpu', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "else:\n",
    "    with tf.device('/device:CPU:0'):\n",
    "        X = tf.placeholder(\"float\", [batch_size, 32, 32, 3])\n",
    "        Y = tf.placeholder(\"float\", [batch_size, 10])\n",
    "        label = tf.placeholder(\"int64\",[batch_size])\n",
    "        learning_rate = tf.placeholder(\"float\", [])\n",
    "        \n",
    "        global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        \n",
    "        net = resnet(X,20)\n",
    "        \n",
    "        cross_entropy = -tf.reduce_sum(Y*tf.log(net))\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        correct_prediction = tf.equal(label,tf.argmax(net,axis=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        \n",
    "        opt = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "        train_op = opt.minimize(cross_entropy)\n",
    "        \n",
    "    merged = tf.summary.merge_all()\n",
    "    sess = tf.Session()\n",
    "    writer = tf.summary.FileWriter(summaries_dir + '/cpu', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 294.34454345703125 accuracy : 0.1171875\n",
      "loss : 296.0260314941406 accuracy : 0.078125\n",
      "loss : 299.44464111328125 accuracy : 0.109375\n",
      "loss : 299.57916259765625 accuracy : 0.0859375\n",
      "loss : 296.91839599609375 accuracy : 0.0625\n",
      "loss : 296.551025390625 accuracy : 0.125\n",
      "loss : 296.4378967285156 accuracy : 0.109375\n",
      "loss : 300.7614440917969 accuracy : 0.0703125\n",
      "loss : 293.95721435546875 accuracy : 0.1328125\n",
      "loss : 292.79217529296875 accuracy : 0.125\n",
      "loss : 296.4313659667969 accuracy : 0.140625\n",
      "loss : 297.61474609375 accuracy : 0.1015625\n",
      "loss : 298.6258239746094 accuracy : 0.109375\n",
      "loss : 293.48748779296875 accuracy : 0.1171875\n",
      "loss : 296.3218994140625 accuracy : 0.0625\n",
      "loss : 299.706787109375 accuracy : 0.0859375\n",
      "loss : 296.920166015625 accuracy : 0.0625\n",
      "loss : 295.7039794921875 accuracy : 0.09375\n",
      "loss : 296.4648742675781 accuracy : 0.1171875\n",
      "loss : 298.9210510253906 accuracy : 0.109375\n",
      "loss : 296.5628356933594 accuracy : 0.0703125\n",
      "loss : 296.032958984375 accuracy : 0.0703125\n",
      "loss : 297.0374755859375 accuracy : 0.109375\n",
      "loss : 294.4471130371094 accuracy : 0.109375\n",
      "loss : 294.0190734863281 accuracy : 0.046875\n",
      "loss : 294.95697021484375 accuracy : 0.1171875\n",
      "loss : 295.45233154296875 accuracy : 0.09375\n",
      "loss : 299.16693115234375 accuracy : 0.1015625\n",
      "loss : 297.41363525390625 accuracy : 0.1015625\n",
      "loss : 294.5863037109375 accuracy : 0.140625\n",
      "loss : 295.66302490234375 accuracy : 0.109375\n",
      "loss : 294.9060363769531 accuracy : 0.1484375\n",
      "loss : 299.38427734375 accuracy : 0.09375\n",
      "loss : 296.4047546386719 accuracy : 0.0703125\n",
      "loss : 296.8958740234375 accuracy : 0.0859375\n",
      "loss : 294.9419250488281 accuracy : 0.125\n",
      "loss : 292.4085998535156 accuracy : 0.125\n",
      "loss : 296.869140625 accuracy : 0.1015625\n",
      "loss : 294.08062744140625 accuracy : 0.1015625\n",
      "loss : 298.817626953125 accuracy : 0.078125\n",
      "loss : 298.21771240234375 accuracy : 0.1015625\n",
      "loss : 295.1111145019531 accuracy : 0.1328125\n",
      "loss : 296.16644287109375 accuracy : 0.1328125\n",
      "loss : 295.20745849609375 accuracy : 0.1015625\n",
      "loss : 295.8376770019531 accuracy : 0.109375\n",
      "loss : 296.1502990722656 accuracy : 0.109375\n",
      "loss : 295.67816162109375 accuracy : 0.078125\n",
      "loss : 299.3201599121094 accuracy : 0.09375\n",
      "loss : 299.2162170410156 accuracy : 0.09375\n",
      "loss : 297.86236572265625 accuracy : 0.09375\n",
      "loss : 295.4980773925781 accuracy : 0.1015625\n",
      "loss : 294.7220764160156 accuracy : 0.1328125\n",
      "loss : 296.4468078613281 accuracy : 0.0703125\n",
      "loss : 294.9284973144531 accuracy : 0.109375\n",
      "loss : 295.81475830078125 accuracy : 0.125\n",
      "loss : 297.20318603515625 accuracy : 0.1015625\n",
      "loss : 299.7384033203125 accuracy : 0.1015625\n",
      "loss : 298.5682067871094 accuracy : 0.0390625\n",
      "loss : 298.77008056640625 accuracy : 0.0859375\n",
      "loss : 296.2050476074219 accuracy : 0.109375\n",
      "loss : 294.880615234375 accuracy : 0.0859375\n",
      "loss : 296.4339294433594 accuracy : 0.0703125\n",
      "loss : 294.611572265625 accuracy : 0.0859375\n",
      "loss : 295.0268249511719 accuracy : 0.1171875\n",
      "loss : 297.4224853515625 accuracy : 0.078125\n",
      "loss : 297.72381591796875 accuracy : 0.078125\n",
      "loss : 296.610595703125 accuracy : 0.125\n",
      "loss : 293.754638671875 accuracy : 0.0703125\n",
      "loss : 299.0650634765625 accuracy : 0.0859375\n",
      "loss : 297.1906433105469 accuracy : 0.109375\n",
      "loss : 294.76129150390625 accuracy : 0.1171875\n",
      "loss : 298.01495361328125 accuracy : 0.0703125\n",
      "loss : 296.1812744140625 accuracy : 0.09375\n",
      "loss : 295.7253112792969 accuracy : 0.125\n",
      "loss : 300.7637939453125 accuracy : 0.078125\n",
      "loss : 296.5971984863281 accuracy : 0.1015625\n",
      "loss : 294.3460388183594 accuracy : 0.1484375\n",
      "loss : 300.8572692871094 accuracy : 0.0703125\n",
      "loss : 297.4192810058594 accuracy : 0.1015625\n",
      "loss : 295.6190185546875 accuracy : 0.109375\n",
      "loss : 294.8453369140625 accuracy : 0.1484375\n",
      "loss : 294.9072570800781 accuracy : 0.078125\n",
      "loss : 297.1357421875 accuracy : 0.078125\n",
      "loss : 297.0062561035156 accuracy : 0.109375\n",
      "loss : 297.5438232421875 accuracy : 0.1015625\n",
      "loss : 298.5533447265625 accuracy : 0.0859375\n",
      "loss : 298.6795654296875 accuracy : 0.09375\n",
      "loss : 295.2691955566406 accuracy : 0.1171875\n",
      "loss : 297.7318115234375 accuracy : 0.1015625\n",
      "loss : 297.87359619140625 accuracy : 0.078125\n",
      "loss : 294.5850830078125 accuracy : 0.1328125\n",
      "loss : 294.50732421875 accuracy : 0.09375\n",
      "loss : 295.524658203125 accuracy : 0.078125\n",
      "loss : 296.0290222167969 accuracy : 0.078125\n",
      "loss : 297.05523681640625 accuracy : 0.125\n",
      "loss : 297.357421875 accuracy : 0.09375\n",
      "loss : 294.42193603515625 accuracy : 0.1328125\n",
      "loss : 296.24774169921875 accuracy : 0.109375\n",
      "loss : 292.7130432128906 accuracy : 0.1484375\n",
      "loss : 295.962158203125 accuracy : 0.1015625\n",
      "loss : 297.9937744140625 accuracy : 0.078125\n",
      "loss : 294.421630859375 accuracy : 0.0859375\n",
      "loss : 298.74127197265625 accuracy : 0.0546875\n",
      "loss : 296.6884460449219 accuracy : 0.0703125\n",
      "loss : 298.0032653808594 accuracy : 0.0859375\n",
      "loss : 294.67535400390625 accuracy : 0.140625\n",
      "loss : 298.5103454589844 accuracy : 0.109375\n",
      "loss : 298.152587890625 accuracy : 0.1015625\n",
      "loss : 295.72216796875 accuracy : 0.125\n",
      "loss : 295.990234375 accuracy : 0.1015625\n",
      "loss : 297.0440673828125 accuracy : 0.09375\n",
      "loss : 297.6617126464844 accuracy : 0.0859375\n",
      "loss : 298.08642578125 accuracy : 0.0703125\n",
      "loss : 292.6329345703125 accuracy : 0.15625\n",
      "loss : 293.4639892578125 accuracy : 0.1015625\n",
      "loss : 294.59906005859375 accuracy : 0.1171875\n",
      "loss : 295.0909423828125 accuracy : 0.0859375\n",
      "loss : 294.11834716796875 accuracy : 0.109375\n",
      "loss : 296.7737731933594 accuracy : 0.0859375\n",
      "loss : 299.202880859375 accuracy : 0.1328125\n",
      "loss : 297.10125732421875 accuracy : 0.0859375\n",
      "loss : 293.9652404785156 accuracy : 0.1015625\n",
      "loss : 294.94342041015625 accuracy : 0.0859375\n",
      "loss : 296.69561767578125 accuracy : 0.1171875\n",
      "loss : 294.6107482910156 accuracy : 0.0859375\n",
      "loss : 295.3266296386719 accuracy : 0.1328125\n",
      "loss : 295.5205078125 accuracy : 0.0859375\n",
      "loss : 294.63568115234375 accuracy : 0.1328125\n",
      "loss : 296.8141174316406 accuracy : 0.1171875\n",
      "loss : 294.3852233886719 accuracy : 0.09375\n",
      "loss : 296.65374755859375 accuracy : 0.109375\n",
      "loss : 294.03997802734375 accuracy : 0.078125\n",
      "loss : 296.0473937988281 accuracy : 0.109375\n",
      "loss : 295.1061706542969 accuracy : 0.1171875\n",
      "loss : 295.7200927734375 accuracy : 0.078125\n",
      "loss : 294.275634765625 accuracy : 0.140625\n",
      "loss : 292.90399169921875 accuracy : 0.1328125\n",
      "loss : 296.82989501953125 accuracy : 0.0859375\n",
      "loss : 296.2472229003906 accuracy : 0.0625\n",
      "loss : 296.7554931640625 accuracy : 0.09375\n",
      "loss : 298.1416931152344 accuracy : 0.1484375\n",
      "loss : 296.4112854003906 accuracy : 0.1328125\n",
      "loss : 296.73419189453125 accuracy : 0.1328125\n",
      "loss : 298.2237854003906 accuracy : 0.1328125\n",
      "loss : 297.619873046875 accuracy : 0.0625\n",
      "loss : 297.6007080078125 accuracy : 0.09375\n",
      "loss : 296.7210388183594 accuracy : 0.125\n",
      "loss : 293.64068603515625 accuracy : 0.1015625\n",
      "loss : 296.4049987792969 accuracy : 0.1171875\n",
      "loss : 294.2207336425781 accuracy : 0.1171875\n",
      "loss : 300.10308837890625 accuracy : 0.0703125\n",
      "loss : 295.0687561035156 accuracy : 0.0546875\n",
      "loss : 292.79278564453125 accuracy : 0.1875\n",
      "loss : 294.2646484375 accuracy : 0.1484375\n",
      "loss : 295.6202392578125 accuracy : 0.109375\n",
      "loss : 295.2947692871094 accuracy : 0.1015625\n",
      "loss : 297.3877868652344 accuracy : 0.09375\n",
      "loss : 296.5433349609375 accuracy : 0.078125\n",
      "loss : 295.4443359375 accuracy : 0.1484375\n",
      "loss : 295.460693359375 accuracy : 0.0625\n",
      "loss : 293.74981689453125 accuracy : 0.109375\n",
      "loss : 297.03802490234375 accuracy : 0.1171875\n",
      "loss : 294.84625244140625 accuracy : 0.140625\n",
      "loss : 297.457275390625 accuracy : 0.09375\n",
      "loss : 294.2767028808594 accuracy : 0.078125\n",
      "loss : 294.91802978515625 accuracy : 0.1015625\n",
      "loss : 294.2367248535156 accuracy : 0.0703125\n",
      "loss : 293.9246826171875 accuracy : 0.140625\n",
      "loss : 296.62591552734375 accuracy : 0.1015625\n",
      "loss : 294.5352783203125 accuracy : 0.109375\n",
      "loss : 296.34100341796875 accuracy : 0.1015625\n",
      "loss : 298.70477294921875 accuracy : 0.09375\n",
      "loss : 297.1814880371094 accuracy : 0.078125\n",
      "loss : 293.2857666015625 accuracy : 0.15625\n",
      "loss : 294.9900207519531 accuracy : 0.1015625\n",
      "loss : 298.1301574707031 accuracy : 0.0390625\n",
      "loss : 296.5880126953125 accuracy : 0.1171875\n",
      "loss : 295.2997131347656 accuracy : 0.1015625\n",
      "loss : 293.21942138671875 accuracy : 0.125\n",
      "loss : 295.1708984375 accuracy : 0.1015625\n",
      "loss : 295.043701171875 accuracy : 0.125\n",
      "loss : 296.09625244140625 accuracy : 0.0703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 293.7008056640625 accuracy : 0.1171875\n",
      "loss : 295.8150939941406 accuracy : 0.0703125\n",
      "loss : 292.630126953125 accuracy : 0.140625\n",
      "loss : 295.2437744140625 accuracy : 0.1015625\n",
      "loss : 294.1252746582031 accuracy : 0.1171875\n",
      "loss : 300.8419189453125 accuracy : 0.09375\n",
      "loss : 295.815185546875 accuracy : 0.109375\n",
      "loss : 294.3324279785156 accuracy : 0.109375\n",
      "loss : 295.1236877441406 accuracy : 0.078125\n",
      "loss : 294.95025634765625 accuracy : 0.1171875\n",
      "loss : 295.55859375 accuracy : 0.0859375\n",
      "loss : 297.3970031738281 accuracy : 0.0703125\n",
      "loss : 296.3607177734375 accuracy : 0.0859375\n",
      "loss : 295.67767333984375 accuracy : 0.109375\n",
      "loss : 293.70947265625 accuracy : 0.1328125\n",
      "loss : 296.41241455078125 accuracy : 0.1015625\n",
      "loss : 295.9024658203125 accuracy : 0.0703125\n",
      "loss : 294.0887451171875 accuracy : 0.140625\n",
      "loss : 295.7059631347656 accuracy : 0.09375\n",
      "loss : 298.8115234375 accuracy : 0.0703125\n",
      "loss : 298.3303527832031 accuracy : 0.0703125\n",
      "loss : 293.5090637207031 accuracy : 0.1171875\n",
      "loss : 296.67578125 accuracy : 0.078125\n",
      "loss : 294.57281494140625 accuracy : 0.1015625\n",
      "loss : 299.5176696777344 accuracy : 0.078125\n",
      "loss : 295.42626953125 accuracy : 0.0859375\n",
      "loss : 297.04766845703125 accuracy : 0.0859375\n",
      "loss : 297.1630554199219 accuracy : 0.0703125\n",
      "loss : 294.9964294433594 accuracy : 0.109375\n",
      "loss : 298.04150390625 accuracy : 0.0703125\n",
      "loss : 294.78460693359375 accuracy : 0.1328125\n",
      "loss : 297.9676513671875 accuracy : 0.03125\n",
      "loss : 293.9224548339844 accuracy : 0.109375\n",
      "loss : 299.31036376953125 accuracy : 0.09375\n",
      "loss : 293.2221374511719 accuracy : 0.1171875\n",
      "loss : 295.5586242675781 accuracy : 0.140625\n",
      "loss : 295.7812194824219 accuracy : 0.078125\n",
      "loss : 297.4007263183594 accuracy : 0.109375\n",
      "loss : 292.9508361816406 accuracy : 0.125\n",
      "loss : 294.64892578125 accuracy : 0.125\n",
      "loss : 294.34210205078125 accuracy : 0.15625\n",
      "loss : 296.25836181640625 accuracy : 0.09375\n",
      "loss : 294.9472351074219 accuracy : 0.109375\n",
      "loss : 294.5998840332031 accuracy : 0.1328125\n",
      "loss : 295.41656494140625 accuracy : 0.09375\n",
      "loss : 294.92254638671875 accuracy : 0.1015625\n",
      "loss : 296.50616455078125 accuracy : 0.1015625\n",
      "loss : 298.27532958984375 accuracy : 0.09375\n",
      "loss : 294.50946044921875 accuracy : 0.1015625\n",
      "loss : 295.2953796386719 accuracy : 0.0625\n",
      "loss : 300.00286865234375 accuracy : 0.0859375\n",
      "loss : 297.78436279296875 accuracy : 0.109375\n",
      "loss : 295.5910949707031 accuracy : 0.109375\n",
      "loss : 294.4107666015625 accuracy : 0.125\n",
      "loss : 295.3511047363281 accuracy : 0.1171875\n",
      "loss : 294.3415222167969 accuracy : 0.09375\n",
      "loss : 295.3740539550781 accuracy : 0.1015625\n",
      "loss : 294.99957275390625 accuracy : 0.109375\n",
      "loss : 294.37335205078125 accuracy : 0.125\n",
      "loss : 295.3103332519531 accuracy : 0.09375\n",
      "loss : 297.21258544921875 accuracy : 0.0703125\n",
      "loss : 296.1229553222656 accuracy : 0.09375\n",
      "loss : 296.6287841796875 accuracy : 0.078125\n",
      "loss : 296.9197692871094 accuracy : 0.0859375\n",
      "loss : 296.4725036621094 accuracy : 0.140625\n",
      "loss : 300.3214111328125 accuracy : 0.1015625\n",
      "loss : 300.2212829589844 accuracy : 0.0625\n",
      "loss : 297.21063232421875 accuracy : 0.109375\n",
      "loss : 294.1479797363281 accuracy : 0.125\n",
      "loss : 293.9410400390625 accuracy : 0.109375\n",
      "loss : 302.00396728515625 accuracy : 0.0703125\n",
      "loss : 297.051025390625 accuracy : 0.1015625\n",
      "loss : 295.9019470214844 accuracy : 0.1015625\n",
      "loss : 296.5881652832031 accuracy : 0.0859375\n",
      "loss : 298.35943603515625 accuracy : 0.0625\n",
      "loss : 289.95648193359375 accuracy : 0.1875\n",
      "loss : 296.17156982421875 accuracy : 0.109375\n",
      "loss : 296.9043273925781 accuracy : 0.0859375\n",
      "loss : 293.7138977050781 accuracy : 0.1484375\n",
      "loss : 296.6941223144531 accuracy : 0.1015625\n",
      "loss : 297.48626708984375 accuracy : 0.0546875\n",
      "loss : 295.5873718261719 accuracy : 0.1015625\n",
      "loss : 297.17987060546875 accuracy : 0.1015625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-158c9051f704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/egpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/egpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/egpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/envs/egpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/egpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Multiple epochs\n",
    "from tqdm import tqdm\n",
    "n_epochs = 1\n",
    "for _ in tqdm(range(n_epochs)):\n",
    "  while True:\n",
    "    try:\n",
    "      randix = np.random.randint(len(X_train),size=batch_size)\n",
    "      x_batch = X_train[randix]\n",
    "      y_batch = y_train[randix]\n",
    "      summary,loss,acc,_ = sess.run([merged,cross_entropy,accuracy,train_op], feed_dict={label: y_batch,X: x_batch, Y: np.eye(10)[y_batch],learning_rate: 0.005})\n",
    "      steps = tf.train.global_step(sess, global_step_tensor)\n",
    "      if steps % 500 == 0:\n",
    "          print(\"loss : {} accuracy : {}\".format(loss,acc))\n",
    "          writer.add_summary(summary, steps)\n",
    "    except ValueError:\n",
    "      print(loss)\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From what i read online, it seems that this implementation of resnet is not very good. It is not that the loss will collapse it is that it is not really learning anything at all.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:egpu]",
   "language": "python",
   "name": "conda-env-egpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
