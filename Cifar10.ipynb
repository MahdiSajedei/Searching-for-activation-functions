{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       label\n",
       "0   1        frog\n",
       "1   2       truck\n",
       "2   3       truck\n",
       "3   4        deer\n",
       "4   5  automobile"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "labels = pd.read_csv(\"/Users/mingliangang/Desktop/cifar10/trainLabels.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label2id = {x:i for i,x in enumerate(list(set(labels[\"label\"])))}\n",
    "id2label = {i:x for i,x in enumerate(list(set(labels[\"label\"])))}\n",
    "labelcon = lambda x: label2id[x]\n",
    "labels['label'] = labels['label'].map(labelcon)\n",
    "labels_ = labels['label'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    1\n",
       "2    1\n",
       "3    9\n",
       "4    2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['label'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, ..., 1, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          frog\n",
       "1         truck\n",
       "2         truck\n",
       "3          deer\n",
       "4    automobile\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['label'].map(lambda x: id2label[x]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "train = np.array([cv2.imread(\"/Users/mingliangang/Desktop/cifar10/train/\"+i) for i in os.listdir(\"/Users/mingliangang/Desktop/cifar10/train\")]).astype(np.float32)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, labels_, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33500, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet Model (CIFAR 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape:0\", shape=(4,), dtype=int32, device=/device:GPU:0)\n"
     ]
    }
   ],
   "source": [
    "from models import resnet\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 128\n",
    "GPU = True\n",
    "summaries_dir = \"/Users/mingliangang/Desktop/resnet2/\"\n",
    "\n",
    "if GPU:\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        X = tf.placeholder(\"float\", [batch_size, 32, 32, 3])\n",
    "        Y = tf.placeholder(\"float\", [batch_size, 10])\n",
    "        label = tf.placeholder(\"int64\",[batch_size])\n",
    "        learning_rate = tf.placeholder(\"float\", [])\n",
    "        \n",
    "        global_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n",
    "        \n",
    "        net = resnet(X,20)\n",
    "        \n",
    "        cross_entropy = -tf.reduce_sum(Y*tf.log(net))\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        correct_prediction = tf.equal(label,tf.argmax(net,axis=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        \n",
    "        opt = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "        train_op = opt.minimize(cross_entropy,global_step=global_step_tensor)\n",
    "        \n",
    "    merged = tf.summary.merge_all()\n",
    "    config = tf.ConfigProto(allow_soft_placement = True)\n",
    "    sess = tf.Session(config = config)\n",
    "    writer = tf.summary.FileWriter(summaries_dir + '/gpu', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "else:\n",
    "    with tf.device('/device:CPU:0'):\n",
    "        X = tf.placeholder(\"float\", [batch_size, 32, 32, 3])\n",
    "        Y = tf.placeholder(\"float\", [batch_size, 10])\n",
    "        label = tf.placeholder(\"int64\",[batch_size])\n",
    "        learning_rate = tf.placeholder(\"float\", [])\n",
    "        \n",
    "        global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        \n",
    "        net = resnet(X,20)\n",
    "        \n",
    "        cross_entropy = -tf.reduce_sum(Y*tf.log(net))\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        correct_prediction = tf.equal(label,tf.argmax(net,axis=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        \n",
    "        opt = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "        train_op = opt.minimize(cross_entropy)\n",
    "        \n",
    "    merged = tf.summary.merge_all()\n",
    "    sess = tf.Session()\n",
    "    writer = tf.summary.FileWriter(summaries_dir + '/cpu', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 296.8796081542969 accuracy : 0.140625\n",
      "loss : 293.93682861328125 accuracy : 0.125\n",
      "loss : 294.0349426269531 accuracy : 0.140625\n",
      "loss : 295.1753845214844 accuracy : 0.1015625\n",
      "loss : 295.8197326660156 accuracy : 0.0390625\n",
      "loss : 294.703369140625 accuracy : 0.078125\n",
      "loss : 294.9972839355469 accuracy : 0.0859375\n",
      "loss : 295.668701171875 accuracy : 0.078125\n",
      "loss : 295.05029296875 accuracy : 0.0703125\n",
      "loss : 294.7466125488281 accuracy : 0.125\n",
      "loss : 293.6047668457031 accuracy : 0.1484375\n",
      "loss : 294.7416076660156 accuracy : 0.0859375\n",
      "loss : 294.7076416015625 accuracy : 0.109375\n",
      "loss : 294.81072998046875 accuracy : 0.125\n",
      "loss : 295.4272155761719 accuracy : 0.09375\n",
      "loss : 294.8186340332031 accuracy : 0.1484375\n",
      "loss : 295.0841064453125 accuracy : 0.1015625\n",
      "loss : 294.94305419921875 accuracy : 0.1015625\n",
      "loss : 294.7513122558594 accuracy : 0.109375\n",
      "loss : 294.7073974609375 accuracy : 0.09375\n",
      "loss : 294.7951965332031 accuracy : 0.1328125\n",
      "loss : 295.5307922363281 accuracy : 0.0859375\n",
      "loss : 295.2213439941406 accuracy : 0.109375\n",
      "loss : 297.6044006347656 accuracy : 0.0703125\n",
      "loss : 295.60064697265625 accuracy : 0.109375\n",
      "loss : 294.6595458984375 accuracy : 0.1328125\n",
      "loss : 293.4214782714844 accuracy : 0.1171875\n",
      "loss : 295.33172607421875 accuracy : 0.1015625\n",
      "loss : 295.71209716796875 accuracy : 0.109375\n",
      "loss : 295.30792236328125 accuracy : 0.0703125\n",
      "loss : 295.85223388671875 accuracy : 0.078125\n",
      "loss : 294.43865966796875 accuracy : 0.09375\n",
      "loss : 294.8775939941406 accuracy : 0.1015625\n",
      "loss : 294.258056640625 accuracy : 0.0859375\n",
      "loss : 298.1695251464844 accuracy : 0.078125\n",
      "loss : 295.0568542480469 accuracy : 0.03125\n",
      "loss : 294.9692077636719 accuracy : 0.09375\n",
      "loss : 295.3370056152344 accuracy : 0.125\n",
      "loss : 294.69293212890625 accuracy : 0.1328125\n",
      "loss : 294.1756286621094 accuracy : 0.1171875\n",
      "loss : 295.3905029296875 accuracy : 0.0703125\n",
      "loss : 295.7392578125 accuracy : 0.078125\n",
      "loss : 295.3792724609375 accuracy : 0.078125\n",
      "loss : 294.8644104003906 accuracy : 0.09375\n",
      "loss : 295.17498779296875 accuracy : 0.125\n",
      "loss : 296.4944763183594 accuracy : 0.0546875\n",
      "loss : 294.81512451171875 accuracy : 0.1328125\n",
      "loss : 295.21661376953125 accuracy : 0.0703125\n",
      "loss : 295.07861328125 accuracy : 0.109375\n",
      "loss : 294.66705322265625 accuracy : 0.1171875\n",
      "loss : 294.4839172363281 accuracy : 0.1328125\n",
      "loss : 296.5046691894531 accuracy : 0.0703125\n",
      "loss : 295.07977294921875 accuracy : 0.09375\n",
      "loss : 294.3858947753906 accuracy : 0.109375\n",
      "loss : 296.1319580078125 accuracy : 0.0703125\n",
      "loss : 295.82281494140625 accuracy : 0.0625\n",
      "loss : 294.4566650390625 accuracy : 0.109375\n",
      "loss : 294.13818359375 accuracy : 0.125\n",
      "loss : 294.4034118652344 accuracy : 0.1484375\n",
      "loss : 294.72625732421875 accuracy : 0.1171875\n",
      "loss : 294.7679748535156 accuracy : 0.0859375\n",
      "loss : 295.19384765625 accuracy : 0.0859375\n",
      "loss : 294.7244873046875 accuracy : 0.109375\n",
      "loss : 294.9034729003906 accuracy : 0.09375\n",
      "loss : 294.9409484863281 accuracy : 0.078125\n",
      "loss : 295.7515563964844 accuracy : 0.0859375\n",
      "loss : 294.76263427734375 accuracy : 0.09375\n",
      "loss : 295.78515625 accuracy : 0.0625\n",
      "loss : 294.9945983886719 accuracy : 0.0625\n",
      "loss : 293.87109375 accuracy : 0.1171875\n",
      "loss : 296.3990173339844 accuracy : 0.0625\n",
      "loss : 294.68212890625 accuracy : 0.0859375\n",
      "loss : 294.7000732421875 accuracy : 0.0859375\n",
      "loss : 295.8670654296875 accuracy : 0.078125\n",
      "loss : 294.8890075683594 accuracy : 0.1015625\n",
      "loss : 295.2486877441406 accuracy : 0.1171875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2b545481c708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/egpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/egpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/egpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/envs/egpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/egpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Multiple epochs\n",
    "from tqdm import tqdm\n",
    "n_epochs = 1\n",
    "for _ in tqdm(range(n_epochs)):\n",
    "  while True:\n",
    "    try:\n",
    "      randix = np.random.randint(len(X_train),size=batch_size)\n",
    "      x_batch = X_train[randix]\n",
    "      y_batch = y_train[randix]\n",
    "      summary,loss,acc,_ = sess.run([merged,cross_entropy,accuracy,train_op], feed_dict={label: y_batch,X: x_batch, Y: np.eye(10)[y_batch],learning_rate: 0.001})\n",
    "      steps = tf.train.global_step(sess, global_step_tensor)\n",
    "      if steps % 100 == 0:\n",
    "          print(\"loss : {} accuracy : {}\".format(loss,acc))\n",
    "          writer.add_summary(summary, steps)\n",
    "    except ValueError:\n",
    "      print(loss)\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From what i read online, it seems that this implementation of resnet is not very good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:egpu]",
   "language": "python",
   "name": "conda-env-egpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
